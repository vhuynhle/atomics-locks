#+TITLE: Memory Ordering
#+LATEX_HEADER: \usepackage[scaled]{helvet} \renewcommand\familydefault{\sfdefault}
#+LATEX_HEADER_EXTRA: \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}


* Reordering and Optimizations

- The compiler and processor may modify and re-order instructions of a program to make it faster, as long as that optimization does not change the result of the program.
- The verification of the same result does not consider other threads.
- We have to tell the compiler and processor what they can and can't do with our atomic operations.
- Memory ordering allows us to do that.


** Example

Given the following source code, the compiler may combine the increment operations on ~a~ into a single operation.

#+begin_src rust
  fn f(a: &mut i32, b: &mut i32) {
      *a += 1;
      *b += 1;
      *a += 1;
  }
#+end_src

A possible optimization:
#+begin_src rust
  fn f(a: &mut i32, b: &mut i32) {
      *a += 2;
      *b += 1;
  }
#+end_src

Later, the processor may decide to increase ~b~ before ~a~, e.g., because ~b~ is available in cache but ~a~ has to be fetched from RAM.

* Happens-before relationship

** The basic rule
The basic rule is that, within the same thread, everything happens in order.

** Relaxed memory ordering
The relaxed memory ordering does not guarantee any happens-before relationships across threads.

** Example: the basic rule and relaxed memory ordering

#+begin_src rust
  static X: AtomicI32 = AtomicI32::new(0);
  static Y: AtomicI32 = AtomicI32::new(0);

  fn a() {
      X.store(10, Relaxed); // 1
      Y.store(20, Relaxed); // 2
  }

  fn b() {
      let y = Y.load(Relaxed); // 3
      let x = X.load(Relaxed); // 4

      println("{x} {y}");
  }
#+end_src

According to the basic rule:

- (1) happens before (2)
- (3) happens before (4)

Because we use relaxed memory ordering, there are no other happens-before relationships among the statements (1), (2), (3), (4).

The possible outputs are:

1. "10 20", e.g., if the operations are in the order (1)(2)(3)(4)
2. "0 0", e.g., if the operations are in the order (3)(4)(1)(2)
3. "10 0", e.g., if the operations are in the order (1)(3)(2)(4), (1)(3)(4)(2), (3)(1)(4)(2), (3)(4)(1)(2).
4. "0 20". There is /no global consistent order/ of the operations that can result in this output. The reason is that:
   + From the perspective of thread ~a~, (1) happens-before (2) (according to the basic rule), however,
   + From the perspective of thread ~b~, (2) may appear to happen before (1).

With the demo program [[file:src/bin/relaxed_ordering.rs]], only outcomes 1, 2, 3, 4 are observable after several test runs. However, that is not guaranteed.

** Spawning and Joining
Spawning a thread creates a happens-before relationship between what happens before and after the ~spawn()~ function call.

Joining a thread creates a happens-before relationship between what happens before and after the ~join()~ function call.

For example:

#+begin_src rust
    static X: AtomicI32 = AtomicI32::new(0);

  fn main() {
      X.store(1, Relaxed);      // (1)
      let t = thread::spawn(f);
      X.store(2, Relaxed);      // (2)
      t.join().unwrap();
      X.store(3, Relaxed);      // (3)
  }

  fn f() {
      let x = X.load(Relaxed);  // (4)
      assert!(x == 1 || x == 2);
  }
#+end_src

In this example:
- The ~spawn()~ function call establishes the happens-before relationship between (1) and (2) and between (1) and (4).
- The ~join()~ function call establishes the happens-before relationship between (2) and (3) and between (4) and (3).=

* Relaxed Ordering

The relaxed ordering guarantees a total modification order of each individual atomic variable.

** Example

#+begin_src cpp
  static X: AtomicI32 = AtomicI32::new(0);

  fn a() {
      X.fetch_add(5, Relaxed);
      X.fetch_add(10, Relaxed);
  }

  fn b() {
      let a = X.load(Relaxed);
      let b = X.load(Relaxed);
      let c = X.load(Relaxed);
      let d = X.load(Relaxed);
      println!("{a} {b} {c} {d}");
  }
#+end_src

Due to the total modification order guarantee on ~X~, there's only one possible modification order: 0 $\rightarrow$ 5 $\rightarrow$ 15. Some possible outputs with this modification order:

- 0 0 0 0
- 0 0 0 5
- 0 0 5 15
- ...
- 15 15 15 15

Now considering splitting ~a~ into two functions running in two threads:
#+begin_src rust
  fn a1() {
      X.fetch_add(5, Relaxed);
  }

  fn a2() {
      X.fetch_add(10, Relaxed);
  }
#+end_src

There are 2 possible modification orders:

- 0 $\rightarrow$ 5 $\rightarrow$ 15
- 0 $\rightarrow$ 10 $\rightarrow$ 15

Possible outputs are:
- 0 0 0 0
- 0 0 0 5
- 0 0 0 10
- 0 0 5 15
- 0 0 10 15
- ...
- 15 15 15 15

* Release and Acquire Ordering

#+begin_quote
A happens-before relationship is formed when an acquire-load operation observes the result of a release-store operation.
#+end_quote

* Sequentially Consistent Ordering

This memory ordering guarantees:

1. acquire ordering for loads,
2. release ordering for stores,
3. a globally consistent order of operations

#+begin_quote
Only when both sides of a happens-before relationship use SeqCst ordering is it guaranteed to be consistent with the single total order of SeqCst operations.
#+end_quote

* Fences

** Release and acquire fences

The store of a release-acquire relationship

#+begin_src rust
  a.store(1, Release);
#+end_src

is equivalent to

#+begin_src rust
  fence(Release);
  a.store(1, Relaxed);
#+end_src

The load of a release-acquire relationship

#+begin_src rust
  a.load(Acquire);
#+end_src

is equivalent to

#+begin_src rust
  a.load(Relaxed);
  fence(Acquire);
#+end_src



Consider two threads:
#+begin_src rust
  // Thread 1
  fence(Release);
  A.store(1, Relaxed);
  B.store(2, Relaxed);
  C.store(3, Relaxed);
#+end_src

#+begin_src rust
  // Thread 2
  A.load(Relaxed);
  B.load(Relaxed);
  C.load(Relaxed);
  fence(Acquire);
#+end_src

If any of the load operations on thread 2 loads the value from the corresponding
store operation on thread 1, the release fence happens-before the acquire fence.
